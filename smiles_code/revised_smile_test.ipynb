{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import codecs\n", "from SmilesPE.tokenizer import *\n", "from SmilesPE.pretokenizer import atomwise_tokenizer\n", "from hdlib.space import Vector\n", "from hdlib.space import Space\n", "from hdlib.arithmetic import bind, bundle\n", "from collections import Counter\n", "import pandas as pd\n", "import math"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["instance_proportion = dict()\n", "filtered_proportion = dict()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df = pd.read_csv(\"tox21.csv\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for index, row in df.iterrows():\n", "    zero_count = 0\n", "    one_count = 0\n", "    smile_str = df.iloc[index, 13]\n", "    for i in range(0, 12):\n", "        value = df.iloc[index, i]\n", "        if pd.isnull(value):\n", "            continue\n", "        else:\n", "            if (value == 0):\n", "                zero_count += 1\n", "            if (value == 1):\n", "                one_count += 1\n", "    instance_proportion[smile_str] = [zero_count / (zero_count + one_count), one_count / (zero_count + one_count)]\n", "    zero_count = 0\n", "    one_count = 0"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for key, value in instance_proportion.items():\n", "    ratio = min(value) / max(value)\n", "    if (ratio >= 0.35):\n", "        filtered_proportion[key] = ratio"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["shared_space = Space()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["pieces = list()\n", "culmination_vec_list = dict()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for key in filtered_proportion.keys():\n", "    tokens = atomwise_tokenizer(key)\n", "    pieces.extend(tokens)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["shared_space.bulk_insert(pieces)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for key in filtered_proportion.keys():\n", "    tokens = list(atomwise_tokenizer(key))\n", "    if (len(tokens) < 2):\n", "        culmination_vec_list[key] = shared_space.get(names=[tokens[0]])[0]\n", "    else:\n", "        token_vec0 = shared_space.get(names=[tokens[0]])[0]\n", "        token_vec1 = shared_space.get(names=[tokens[1]])[0]\n", "        token_vec0.permute(rotate_by=0)\n", "        token_vec1.permute(rotate_by=1)\n", "        culmination = bind(token_vec0, token_vec1)\n", "        for i in range(2, len(tokens)):\n", "            current_vec = shared_space.get(names=[tokens[i]])[0]\n", "            current_vec.permute(rotate_by=i)\n", "            culmination = bind(culmination, current_vec)\n", "        culmination_vec_list[key] = culmination"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["vectors_only = list(culmination_vec_list.values())"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class_vec = bundle(vectors_only[0], vectors_only[1])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for i in range(2, len(vectors_only)):\n", "    current_vec = vectors_only[i]\n", "    class_vec = bundle(class_vec, current_vec)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(class_vec)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def encode_single_smiles(smi, vec_space):\n", "    tokens = atomwise_tokenizer(smi)\n", "    if len(tokens) == 1:\n", "        return vec_space.get(names=[tokens[0]])[0]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    token_vec0 = vec_space.get(names=[tokens[0]])[0]\n", "    token_vec1 = vec_space.get(names=[tokens[1]])[0]\n", "    token_vec0.permute(rotate_by=0)\n", "    token_vec1.permute(rotate_by=1)\n", "    culmination = bind(token_vec0, token_vec1)\n", "    for i in range(2, len(tokens)):\n", "        current_vec = vec_space.get(names=[tokens[i]])[0]\n", "        current_vec.permute(rotate_by=i)\n", "        culmination = bind(culmination, current_vec)\n", "    return culmination"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["toxic_ex = \"C#N\"\n", "nontoxic_ex = \"O\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["toxic_ex_vec = encode_single_smiles(toxic_ex, shared_space)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["nontoxic_ex_vec = encode_single_smiles(nontoxic_ex, shared_space)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(f\"{toxic_ex_vec.dist(class_vec, method='cosine')}\\n\")\n", "print(f\"{nontoxic_ex_vec.dist(class_vec, method='cosine')}\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if toxic_ex_vec.dist(class_vec, method='cosine') < nontoxic_ex_vec.dist(class_vec, method='cosine'):\n", "    print(\"The toxic molecule is closer to \\\"s\\\" than the non-toxic one\")\n", "else:\n", "    print(\"The non-toxic molecule is closer to \\\"s\\\" than the toxic one\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    "]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}