{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "from SmilesPE.pretokenizer import atomwise_tokenizer\n", "from hdlib.space import Vector, Space\n", "from hdlib.arithmetic import bundle, bind\n", "import random"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df = pd.read_csv(\"tox21.csv\")\n", "df = df.dropna(subset=[\"NR-ER-LBD\"]).reset_index(drop=True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["zero_set = list()\n", "one_set = list()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for i, row in df.iterrows():\n", "    val = row['NR-ER-LBD']\n", "    smiles = row['smiles']\n", "    if val == 1:\n", "        one_set.append(smiles)\n", "    else:\n", "        zero_set.append(smiles)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["zero_sample = random.sample(zero_set, 100)\n", "one_sample = random.sample(one_set, 100)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["zero_shared_space = Space()\n", "one_shared_space = Space()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def encode_sample_set(sample, shared_space):\n", "    all_tokens = list()\n", "    str_vec = dict()\n", "    for hd_vec in sample:\n", "        tokens = atomwise_tokenizer(hd_vec)\n", "        all_tokens.extend(tokens)\n", "    \n", "    shared_space.bulk_insert(all_tokens)\n", "    for hd_vec in sample:\n", "        cur_tokens = atomwise_tokenizer(hd_vec)\n", "        if len(cur_tokens) == 1:\n", "            return shared_space.get(names=[cur_tokens[0]])[0]\n", "        token_vec0 = shared_space.get(names=[cur_tokens[0]])[0]\n", "        token_vec1 = shared_space.get(names=[cur_tokens[1]])[0]\n", "        token_vec0.permute(rotate_by=0)\n", "        token_vec1.permute(rotate_by=1)\n", "        culmination = bind(token_vec0, token_vec1)\n", "        for i in range(2, len(cur_tokens)):\n", "            current_vec = shared_space.get(names=[cur_tokens[i]])[0]\n", "            current_vec.permute(rotate_by=i)\n", "            culmination = bind(culmination, current_vec)\n", "        \n", "        str_vec[hd_vec] = culmination\n", "    mol_vecs = list(str_vec.values())\n", "    class_vec = bundle(mol_vecs[0], mol_vecs[1])\n", "    for i in range(2, len(mol_vecs)):\n", "        current_vec = mol_vecs[i]\n", "        class_vec = bundle(class_vec, current_vec)\n", "    return class_vec"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["toxic_class_vec = encode_sample_set(zero_sample, zero_shared_space)\n", "nontoxic_class_vec = encode_sample_set(one_sample, one_shared_space)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(toxic_class_vec)\n", "print(nontoxic_class_vec)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}