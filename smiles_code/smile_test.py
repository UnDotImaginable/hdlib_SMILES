import codecs
from SmilesPE.tokenizer import *
from SmilesPE.pretokenizer import atomwise_tokenizer
from hdlib.space import Vector
from hdlib.space import Space
from hdlib.arithmetic import bind, bundle
from collections import Counter
from random import randint
import numpy as np
from hdlib.model import MLModel

shared_space = Space()

def encode_smiles_batch(smiles_list, vec_space):
    molecule_vectors = {}

    for smi in smiles_list:
        tokens = atomwise_tokenizer(smi)

        make_unique = [f"{token} {i}" for i, token in enumerate(tokens)]
        vec_space.bulk_insert(make_unique)

        first_vec = vec_space.get(names=[make_unique[0]])[0]
        second_vec = vec_space.get(names=[make_unique[1]])[0]
        culmination = bind(first_vec, second_vec)

        for i in range(2, len(make_unique)):
            current_vec = vec_space.get(names=[make_unique[i]])[0]
            culmination = bind(culmination, current_vec)

        molecule_vectors[smi] = culmination
    
    culmination_vecs_list = list(molecule_vectors.values())

    final_culmination = bundle(culmination_vecs_list[0], culmination_vecs_list[1])

    for i in range(2, len(culmination_vecs_list)):
        current_vec = culmination_vecs_list[i]
        final_culmination = bundle(final_culmination, current_vec)


    return final_culmination


def encode_single_smiles(smi, vec_space):
    tokens = atomwise_tokenizer(smi)
    print(tokens)

    make_unique = [f"{token} {i}" for i, token in enumerate(tokens)]
    vec_space.bulk_insert(make_unique)

    first_vec = vec_space.get(names=[make_unique[0]])[0]
    second_vec = vec_space.get(names=[make_unique[1]])[0]
    culmination = bind(first_vec, second_vec)

    for i in range(2, len(make_unique)):
        current_vec = vec_space.get(names=[make_unique[i]])[0]
        culmination = bind(culmination, current_vec)

    return culmination




# List of random TOXIC molecules generated by ChatGPT
toxic_smiles = [
    "c1ccccc1",              # Benzene
    "c1ccccc1N",             # Aniline
    "c1ccc(cc1)[N+](=O)[O-]",# Nitrobenzene
    "C=O",                   # Formaldehyde
    "C(Cl)(Cl)(Cl)Cl",       # Carbon tetrachloride
    "C=CC#N",                # Acrylonitrile
    "C=Cl",                  # Vinyl chloride
    "Cc1ccccc1",             # Toluene
    "COS(=O)(=O)OC",         # Dimethyl sulfate
    "C(Cl)(Cl)Cl"            # Chloroform
]


t = encode_single_smiles(toxic_smiles[0], shared_space)
print(t)
print(shared_space.memory())

toxic_ex = "C(Cl)(Cl)(Cl)Cl"
nontoxic_ex = "OC(CO)CO"

s = encode_smiles_batch(toxic_smiles, shared_space)
s.normalize()

toxic_ex_vec = encode_single_smiles(toxic_ex, shared_space)
toxic_ex_vec.normalize()

nontoxic_ex_vec = encode_single_smiles(nontoxic_ex, shared_space)
nontoxic_ex_vec.normalize()

print(f"{toxic_ex_vec.dist(s, method='cosine')}\n")
print(f"{nontoxic_ex_vec.dist(s, method='cosine')}")

if toxic_ex_vec.dist(s, method='cosine') < nontoxic_ex_vec.dist(s, method='cosine'):
    print("The toxic molecule is closer to \"s\" than the non-toxic one")
else:
    print("The non-toxic molecule is closer to \"s\" than the toxic one")
