{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "from SmilesPE.pretokenizer import atomwise_tokenizer\n", "from hdlib.space import Vector, Space\n", "from hdlib.arithmetic import bundle, bind\n", "from hdlib.model import MLModel\n", "import random\n", "from sklearn import metrics"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["memory = Space() # ITEM MEMORY"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df = pd.read_csv(\"tox21.csv\")\n", "df = df.dropna(subset=[\"NR-ER-LBD\"]).reset_index(drop=True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["all_entries = list()\n", "to_insert = list()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for i, row in df.iterrows():\n", "    val = row['NR-ER-LBD']\n", "    smiles = row['smiles']\n", "    all_entries.append((val, smiles))\n", "    tokens = atomwise_tokenizer(smiles)\n", "    to_insert.extend(tokens)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["memory.bulk_insert(to_insert)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["random.shuffle(all_entries)\n", "split_index = int(0.8 * len(all_entries))\n", "sample_80 = all_entries[:split_index]\n", "sample_20 = all_entries[split_index:]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["zero_vecs = [all_entries[i][1] for i in range(0, len(sample_80)) if all_entries[i][0] == 0]\n", "one_vecs = [all_entries[i][1] for i in range(0, len(sample_80)) if all_entries[i][0] == 1]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def encode_sample(sample, shared_space):\n", "    str_vec = dict()\n", "    for hd_vec in sample:\n", "        cur_tokens = atomwise_tokenizer(hd_vec)\n", "        if len(cur_tokens) == 1:\n", "            return shared_space.get(names=[cur_tokens[0]])[0]\n", "        token_vec0 = shared_space.get(names=[cur_tokens[0]])[0]\n", "        token_vec1 = shared_space.get(names=[cur_tokens[1]])[0]\n", "        token_vec0.permute(rotate_by=0)\n", "        token_vec1.permute(rotate_by=1)\n", "        culmination = bind(token_vec0, token_vec1)\n", "        for i in range(2, len(cur_tokens)):\n", "            current_vec = shared_space.get(names=[cur_tokens[i]])[0]\n", "            current_vec.permute(rotate_by=i)\n", "            culmination = bind(culmination, current_vec)\n", "        \n", "        str_vec[hd_vec] = culmination\n", "    mol_vecs = list(str_vec.values())\n", "    class_vec = bind(mol_vecs[0], mol_vecs[1])\n", "    for i in range(2, len(mol_vecs)):\n", "        current_vec = mol_vecs[i]\n", "        class_vec = bind(class_vec, current_vec)\n", "    return class_vec\n", "    "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def encode_smi(smiles, shared_space):\n", "    tokens = atomwise_tokenizer(smiles)\n", "    \n", "    if len(tokens) == 1:\n", "        return shared_space.get(names=[tokens[0]])[0]\n", "    \n", "    vec0 = shared_space.get(names=[tokens[0]])[0]\n", "    vec1 = shared_space.get(names=[tokens[1]])[0]\n", "    \n", "    vec0.permute(rotate_by=0)\n", "    vec1.permute(rotate_by=1)\n", "    \n", "    result = bind(vec0, vec1)\n", "    \n", "    for i in range(2, len(tokens)):\n", "        v = shared_space.get(names=[tokens[i]])[0]\n", "        v.permute(rotate_by=i)\n", "        result = bind(result, v)\n", "    \n", "    return result"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["zero_cv = encode_sample(zero_vecs, memory)\n", "one_cv = encode_sample(one_vecs, memory)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now, we have our \"0\" class vector, our \"1\" class vector, and item memory (from up above)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["real_vs_pred = dict()\n", "for i in range(0, len(sample_20)):\n", "    vec_rep = encode_smi(sample_20[i][1], memory)\n", "    distance_to_0 = vec_rep.dist(zero_cv, method=\"cosine\")\n", "    distance_to_1 = vec_rep.dist(one_cv, method=\"cosine\")\n", "    prediction = 0 if distance_to_0 < distance_to_1 else 1\n", "    real_vs_pred[sample_20[i][1]] = (sample_20[i][0], prediction)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["rvp_vals = list(real_vs_pred.values())"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["desired_index = 1\n", "real = [t[0] for t in rvp_vals]\n", "pred = [t[1] for t in rvp_vals]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["cm = metrics.confusion_matrix(real, pred)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(cm)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}